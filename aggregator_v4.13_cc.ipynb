{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Subject Data Aggregator v4.13_cc\n",
    "\n",
    "This notebook loads aggregated subject CSV files and merges them into a single mega_df for large-scale cross-subject analysis.\n",
    "\n",
    "## Workflow:\n",
    "1. **Scan** - Find all aggregated CSV files (e.g., `CA_Cvc_25.11.19.csv`, `CI101_Cvc_25.11.19.csv`)\n",
    "2. **Load** - Read each CSV and add subject_id column\n",
    "3. **Merge** - Combine into mega_df\n",
    "4. **Analyze** - Use existing analysis tools for cross-subject comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, shapiro, levene, pearsonr, spearmanr\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CSV File Scanner\n",
    "\n",
    "Scans specified directories for aggregated subject CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_subject_csvs(base_directory, pattern='*_C*c_*.csv'):\n",
    "    \"\"\"\n",
    "    Scans directory tree for aggregated subject CSV files.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_directory : str or Path\n",
    "        Root directory to search for CSV files\n",
    "    pattern : str\n",
    "        Glob pattern to match CSV filenames (default: '*_C*c_*.csv')\n",
    "        Examples: 'CA_Cvc_25.11.19.csv', 'CI101_CVC_25.11.19.csv'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list of dict\n",
    "        List containing {subject_id, filepath} for each found file\n",
    "    \"\"\"\n",
    "    base_path = Path(base_directory)\n",
    "    \n",
    "    if not base_path.exists():\n",
    "        print(f\"Error: Directory '{base_directory}' does not exist\")\n",
    "        return []\n",
    "    \n",
    "    # Find all matching CSV files recursively\n",
    "    csv_files = list(base_path.rglob(pattern))\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found matching pattern '{pattern}' in {base_directory}\")\n",
    "        return []\n",
    "    \n",
    "    # Extract subject IDs from filenames\n",
    "    results = []\n",
    "    for csv_path in csv_files:\n",
    "        # Extract subject_id from filename (before first underscore)\n",
    "        filename = csv_path.name\n",
    "        subject_id = filename.split('_')[0]\n",
    "        \n",
    "        results.append({\n",
    "            'subject_id': subject_id,\n",
    "            'filename': filename,\n",
    "            'filepath': csv_path\n",
    "        })\n",
    "    \n",
    "    # Sort by subject_id\n",
    "    results.sort(key=lambda x: x['subject_id'])\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Found {len(results)} subject CSV files\")\n",
    "    print(f\"{'='*70}\")\n",
    "    for r in results:\n",
    "        print(f\"  {r['subject_id']:10s} -> {r['filename']}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test the scanner (update path as needed)\n",
    "# found_files = scan_subject_csvs('/path/to/your/data/directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-Subject CSV Loader\n",
    "\n",
    "Loads all subject CSV files and merges them into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_merge_subjects(base_directory, pattern='*_C*c_*.csv', verbose=True):\n",
    "    \"\"\"\n",
    "    Loads all subject CSV files and merges into single mega_df.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_directory : str or Path\n",
    "        Root directory containing subject CSV files\n",
    "    pattern : str\n",
    "        Glob pattern for CSV files\n",
    "    verbose : bool\n",
    "        Print loading progress\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Merged dataframe with all subjects (includes 'subject_id' column)\n",
    "    \"\"\"\n",
    "    # Scan for CSV files\n",
    "    found_files = scan_subject_csvs(base_directory, pattern)\n",
    "    \n",
    "    if not found_files:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Load each CSV and add subject_id\n",
    "    all_data = []\n",
    "    load_stats = []\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Loading subject data...\")\n",
    "        print(f\"{'='*70}\")\n",
    "    \n",
    "    for file_info in found_files:\n",
    "        subject_id = file_info['subject_id']\n",
    "        filepath = file_info['filepath']\n",
    "        \n",
    "        try:\n",
    "            # Load CSV\n",
    "            df = pd.read_csv(filepath)\n",
    "            \n",
    "            # Add subject_id column\n",
    "            df['subject_id'] = subject_id\n",
    "            \n",
    "            # Track data types present\n",
    "            tasks_present = df['task'].unique() if 'task' in df.columns else []\n",
    "            \n",
    "            all_data.append(df)\n",
    "            \n",
    "            load_stats.append({\n",
    "                'subject_id': subject_id,\n",
    "                'n_trials': len(df),\n",
    "                'tasks': ', '.join(tasks_present)\n",
    "            })\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"  {subject_id:10s} | {len(df):5d} trials | {', '.join(tasks_present)}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR loading {subject_id}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Merge all subjects\n",
    "    if all_data:\n",
    "        mega_df = pd.concat(all_data, ignore_index=True, sort=False)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"MEGA_DF CREATED\")\n",
    "            print(f\"{'='*70}\")\n",
    "            print(f\"Total subjects: {mega_df['subject_id'].nunique()}\")\n",
    "            print(f\"Total trials: {len(mega_df):,}\")\n",
    "            if 'task' in mega_df.columns:\n",
    "                print(f\"\\nTask breakdown:\")\n",
    "                for task, count in mega_df['task'].value_counts().items():\n",
    "                    print(f\"  {task:12s}: {count:6,} trials ({count/len(mega_df)*100:.1f}%)\")\n",
    "            print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        return mega_df\n",
    "    else:\n",
    "        print(\"No data loaded\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Example usage:\n",
    "# mega_df = load_and_merge_subjects('/path/to/your/data/directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick Data Explorer\n",
    "\n",
    "Utility functions to explore the merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_mega_df(mega_df):\n",
    "    \"\"\"\n",
    "    Prints comprehensive overview of the mega_df.\n",
    "    \"\"\"\n",
    "    if mega_df.empty:\n",
    "        print(\"DataFrame is empty\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"MEGA_DF OVERVIEW\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Shape: {mega_df.shape[0]:,} rows x {mega_df.shape[1]} columns\")\n",
    "    print(f\"Memory: {mega_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Subject breakdown\n",
    "    print(f\"\\nSubjects ({mega_df['subject_id'].nunique()}):\")\n",
    "    subject_counts = mega_df['subject_id'].value_counts().sort_index()\n",
    "    for subj, count in subject_counts.items():\n",
    "        print(f\"  {subj:10s}: {count:5,} trials\")\n",
    "    \n",
    "    # Task breakdown\n",
    "    if 'task' in mega_df.columns:\n",
    "        print(f\"\\nTasks:\")\n",
    "        for task, count in mega_df['task'].value_counts().items():\n",
    "            print(f\"  {task:12s}: {count:6,} trials ({count/len(mega_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Column types\n",
    "    print(f\"\\nColumn types:\")\n",
    "    print(f\"  Numeric:  {mega_df.select_dtypes(include=[np.number]).shape[1]}\")\n",
    "    print(f\"  Object:   {mega_df.select_dtypes(include=['object']).shape[1]}\")\n",
    "    print(f\"  Other:    {mega_df.shape[1] - mega_df.select_dtypes(include=[np.number, 'object']).shape[1]}\")\n",
    "    \n",
    "    # Missing data\n",
    "    missing = mega_df.isnull().sum()\n",
    "    missing = missing[missing > 0].sort_values(ascending=False)\n",
    "    if len(missing) > 0:\n",
    "        print(f\"\\nColumns with missing data (top 10):\")\n",
    "        for col, count in missing.head(10).items():\n",
    "            pct = count / len(mega_df) * 100\n",
    "            print(f\"  {col:20s}: {count:6,} ({pct:5.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nColumn names:\")\n",
    "    for i, col in enumerate(mega_df.columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "    \n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Example usage:\n",
    "# explore_mega_df(mega_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Task-Specific Data Extractors\n",
    "\n",
    "Split mega_df by task type for focused analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_task(mega_df):\n",
    "    \"\"\"\n",
    "    Splits mega_df into separate DataFrames by task type.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with keys: 'Consonants', 'Vowels', 'CRM'\n",
    "    \"\"\"\n",
    "    if 'task' not in mega_df.columns:\n",
    "        print(\"Warning: 'task' column not found in mega_df\")\n",
    "        return {}\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    for task in mega_df['task'].unique():\n",
    "        df_task = mega_df[mega_df['task'] == task].copy()\n",
    "        result[task] = df_task\n",
    "        print(f\"{task:12s}: {len(df_task):6,} trials, {df_task['subject_id'].nunique()} subjects\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_subjects_by_task(mega_df, min_trials=10):\n",
    "    \"\"\"\n",
    "    Shows which subjects have data for each task.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    min_trials : int\n",
    "        Minimum trials required to count subject as having task data\n",
    "    \"\"\"\n",
    "    if 'task' not in mega_df.columns:\n",
    "        return\n",
    "    \n",
    "    tasks = mega_df['task'].unique()\n",
    "    subjects = sorted(mega_df['subject_id'].unique())\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Subject x Task Matrix (min {min_trials} trials)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"{'Subject':10s} | \", end='')\n",
    "    for task in tasks:\n",
    "        print(f\"{task:12s} | \", end='')\n",
    "    print()\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for subj in subjects:\n",
    "        print(f\"{subj:10s} | \", end='')\n",
    "        for task in tasks:\n",
    "            n = len(mega_df[(mega_df['subject_id'] == subj) & (mega_df['task'] == task)])\n",
    "            if n >= min_trials:\n",
    "                print(f\"{n:6d} trials | \", end='')\n",
    "            else:\n",
    "                print(f\"{'---':>12s} | \", end='')\n",
    "        print()\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Example usage:\n",
    "# task_dfs = split_by_task(mega_df)\n",
    "# df_consonants = task_dfs['Consonants']\n",
    "# df_vowels = task_dfs['Vowels']\n",
    "# df_crm = task_dfs['CRM']\n",
    "# get_subjects_by_task(mega_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Subject Comparison Tools\n",
    "\n",
    "Analysis functions for comparing metrics across subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_subjects_by_metric(mega_df, metric='score', task_filter=None, \n",
    "                                plot=True, figsize=(12, 6)):\n",
    "    \"\"\"\n",
    "    Compares subjects on a specific metric (e.g., accuracy, RT, score).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    metric : str\n",
    "        Column name to analyze (e.g., 'score', 'rt', 'correct', 'snr')\n",
    "    task_filter : str or None\n",
    "        Filter to specific task ('Consonants', 'Vowels', 'CRM') or None for all\n",
    "    plot : bool\n",
    "        Whether to create visualization\n",
    "    \"\"\"\n",
    "    # Filter by task if specified\n",
    "    if task_filter and 'task' in mega_df.columns:\n",
    "        df = mega_df[mega_df['task'] == task_filter].copy()\n",
    "        title_suffix = f\" ({task_filter})\"\n",
    "    else:\n",
    "        df = mega_df.copy()\n",
    "        title_suffix = \" (All Tasks)\"\n",
    "    \n",
    "    if metric not in df.columns:\n",
    "        print(f\"Error: Column '{metric}' not found in data\")\n",
    "        return\n",
    "    \n",
    "    # Calculate summary stats per subject\n",
    "    summary = df.groupby('subject_id')[metric].agg([\n",
    "        ('mean', 'mean'),\n",
    "        ('std', 'std'),\n",
    "        ('median', 'median'),\n",
    "        ('n', 'count')\n",
    "    ]).round(3)\n",
    "    \n",
    "    summary = summary.sort_values('mean', ascending=False)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Subject Comparison: {metric}{title_suffix}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(summary)\n",
    "    print(f\"\\nOverall mean: {df[metric].mean():.3f}\")\n",
    "    print(f\"Overall std:  {df[metric].std():.3f}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Plot if requested\n",
    "    if plot:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "        \n",
    "        # Bar plot of means\n",
    "        ax1 = axes[0]\n",
    "        summary['mean'].plot(kind='bar', ax=ax1, color='steelblue', alpha=0.7)\n",
    "        ax1.set_title(f'Mean {metric} by Subject{title_suffix}')\n",
    "        ax1.set_xlabel('Subject ID')\n",
    "        ax1.set_ylabel(f'Mean {metric}')\n",
    "        ax1.axhline(df[metric].mean(), color='red', linestyle='--', \n",
    "                    label='Overall Mean', alpha=0.7)\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "        \n",
    "        # Box plot distribution\n",
    "        ax2 = axes[1]\n",
    "        df.boxplot(column=metric, by='subject_id', ax=ax2)\n",
    "        ax2.set_title(f'{metric} Distribution by Subject{title_suffix}')\n",
    "        ax2.set_xlabel('Subject ID')\n",
    "        ax2.set_ylabel(metric)\n",
    "        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "        plt.suptitle('')  # Remove default title\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Example usage:\n",
    "# compare_subjects_by_metric(mega_df, metric='score', task_filter='Consonants')\n",
    "# compare_subjects_by_metric(mega_df, metric='rt', task_filter='Vowels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Subject Group Analysis\n",
    "\n",
    "Tools for analyzing subject groups (e.g., CI vs HS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_subjects(mega_df, custom_categories=None):\n",
    "    \"\"\"\n",
    "    Adds 'subject_group' column based on subject_id prefix.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    custom_categories : dict or None\n",
    "        Custom mapping of patterns to group names\n",
    "        Example: {'CI': 'Cochlear Implant', 'HS': 'Hearing', 'CA': 'Control'}\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        mega_df with added 'subject_group' column\n",
    "    \"\"\"\n",
    "    df = mega_df.copy()\n",
    "    \n",
    "    if custom_categories is None:\n",
    "        # Default categories\n",
    "        def assign_group(subject_id):\n",
    "            if subject_id.startswith('CI'):\n",
    "                return 'CI'\n",
    "            elif subject_id.startswith('HS'):\n",
    "                return 'HS'\n",
    "            elif subject_id.startswith('CA'):\n",
    "                return 'CA'\n",
    "            elif subject_id.startswith('LR'):\n",
    "                return 'LR'\n",
    "            else:\n",
    "                return 'Other'\n",
    "    else:\n",
    "        def assign_group(subject_id):\n",
    "            for pattern, group in custom_categories.items():\n",
    "                if subject_id.startswith(pattern):\n",
    "                    return group\n",
    "            return 'Other'\n",
    "    \n",
    "    df['subject_group'] = df['subject_id'].apply(assign_group)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Subject Groups\")\n",
    "    print(f\"{'='*70}\")\n",
    "    for group in sorted(df['subject_group'].unique()):\n",
    "        subjects = df[df['subject_group'] == group]['subject_id'].unique()\n",
    "        n_trials = len(df[df['subject_group'] == group])\n",
    "        print(f\"{group:15s}: {len(subjects):2d} subjects, {n_trials:6,} trials\")\n",
    "        print(f\"                 {', '.join(sorted(subjects))}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def compare_groups_by_metric(mega_df, metric='score', task_filter=None, \n",
    "                             plot=True, stats_test=True):\n",
    "    \"\"\"\n",
    "    Compares subject groups on a metric with statistical testing.\n",
    "    \n",
    "    Requires 'subject_group' column (use categorize_subjects first).\n",
    "    \"\"\"\n",
    "    if 'subject_group' not in mega_df.columns:\n",
    "        print(\"Error: Run categorize_subjects() first to create subject_group column\")\n",
    "        return\n",
    "    \n",
    "    # Filter by task\n",
    "    if task_filter and 'task' in mega_df.columns:\n",
    "        df = mega_df[mega_df['task'] == task_filter].copy()\n",
    "        title_suffix = f\" ({task_filter})\"\n",
    "    else:\n",
    "        df = mega_df.copy()\n",
    "        title_suffix = \"\"\n",
    "    \n",
    "    if metric not in df.columns:\n",
    "        print(f\"Error: Column '{metric}' not found\")\n",
    "        return\n",
    "    \n",
    "    # Summary by group\n",
    "    summary = df.groupby('subject_group')[metric].agg([\n",
    "        ('mean', 'mean'),\n",
    "        ('std', 'std'),\n",
    "        ('median', 'median'),\n",
    "        ('n', 'count')\n",
    "    ]).round(3)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Group Comparison: {metric}{title_suffix}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(summary)\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Statistical testing\n",
    "    if stats_test:\n",
    "        groups = df['subject_group'].unique()\n",
    "        if len(groups) == 2:\n",
    "            g1, g2 = groups\n",
    "            data1 = df[df['subject_group'] == g1][metric].dropna()\n",
    "            data2 = df[df['subject_group'] == g2][metric].dropna()\n",
    "            \n",
    "            # Mann-Whitney U test (non-parametric)\n",
    "            stat, p = mannwhitneyu(data1, data2, alternative='two-sided')\n",
    "            print(f\"Mann-Whitney U Test:\")\n",
    "            print(f\"  {g1} vs {g2}\")\n",
    "            print(f\"  U-statistic = {stat:.3f}, p-value = {p:.4f}\")\n",
    "            if p < 0.05:\n",
    "                print(f\"  Result: Significant difference (p < 0.05)\")\n",
    "            else:\n",
    "                print(f\"  Result: No significant difference (p >= 0.05)\")\n",
    "            print()\n",
    "    \n",
    "    # Plot\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "        df.boxplot(column=metric, by='subject_group', ax=ax)\n",
    "        ax.set_title(f'{metric} by Subject Group{title_suffix}')\n",
    "        ax.set_xlabel('Subject Group')\n",
    "        ax.set_ylabel(metric)\n",
    "        plt.suptitle('')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Example usage:\n",
    "# mega_df = categorize_subjects(mega_df)\n",
    "# compare_groups_by_metric(mega_df, metric='score', task_filter='Consonants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Utilities\n",
    "\n",
    "Save processed mega_df for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mega_df(mega_df, output_path='mega_df_all_subjects.csv', \n",
    "                 include_timestamp=True):\n",
    "    \"\"\"\n",
    "    Saves mega_df to CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    output_path : str\n",
    "        Output filename\n",
    "    include_timestamp : bool\n",
    "        Add timestamp to filename\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    if include_timestamp:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        base, ext = os.path.splitext(output_path)\n",
    "        output_path = f\"{base}_{timestamp}{ext}\"\n",
    "    \n",
    "    mega_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    file_size = os.path.getsize(output_path) / 1024**2\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"MEGA_DF SAVED\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"File: {output_path}\")\n",
    "    print(f\"Size: {file_size:.2f} MB\")\n",
    "    print(f\"Rows: {len(mega_df):,}\")\n",
    "    print(f\"Cols: {len(mega_df.columns)}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "def load_saved_mega_df(filepath):\n",
    "    \"\"\"\n",
    "    Loads a previously saved mega_df.\n",
    "    \"\"\"\n",
    "    print(f\"Loading {filepath}...\")\n",
    "    mega_df = pd.read_csv(filepath)\n",
    "    print(f\"Loaded {len(mega_df):,} rows, {len(mega_df.columns)} columns\")\n",
    "    return mega_df\n",
    "\n",
    "# Example usage:\n",
    "# save_mega_df(mega_df)\n",
    "# mega_df = load_saved_mega_df('mega_df_all_subjects_20241120_143052.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Main Execution Block\n",
    "\n",
    "**Update the base_directory path and run this cell to load all data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== MAIN EXECUTION =====\n",
    "# Update this path to your data directory containing the aggregated CSV files\n",
    "BASE_DATA_DIR = '/home/user/Disco/Data'  # UPDATE THIS PATH\n",
    "\n",
    "# Load and merge all subject data\n",
    "mega_df = load_and_merge_subjects(\n",
    "    base_directory=BASE_DATA_DIR,\n",
    "    pattern='*_C*c_*.csv',  # Matches CA_Cvc_25.11.19.csv, CI101_CVC_25.11.19.csv, etc.\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Explore the merged dataset\n",
    "if not mega_df.empty:\n",
    "    explore_mega_df(mega_df)\n",
    "    \n",
    "    # Add subject grouping\n",
    "    mega_df = categorize_subjects(mega_df)\n",
    "    \n",
    "    # Show task distribution\n",
    "    print(\"\\nSubject x Task Matrix:\")\n",
    "    get_subjects_by_task(mega_df, min_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Quick Analysis Examples\n",
    "\n",
    "Example analyses using the loaded mega_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Compare accuracy across subjects for Consonants\n",
    "if not mega_df.empty and 'score' in mega_df.columns:\n",
    "    compare_subjects_by_metric(mega_df, metric='score', task_filter='Consonants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Compare reaction times for Vowels\n",
    "if not mega_df.empty and 'rt' in mega_df.columns:\n",
    "    compare_subjects_by_metric(mega_df, metric='rt', task_filter='Vowels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Compare CI vs HS groups\n",
    "if not mega_df.empty and 'subject_group' in mega_df.columns:\n",
    "    compare_groups_by_metric(mega_df, metric='score', task_filter='Consonants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Split data by task for detailed analysis\n",
    "if not mega_df.empty:\n",
    "    task_dfs = split_by_task(mega_df)\n",
    "    \n",
    "    # Access individual task dataframes\n",
    "    if 'Consonants' in task_dfs:\n",
    "        df_consonants = task_dfs['Consonants']\n",
    "        print(f\"\\nConsonants data: {len(df_consonants)} trials\")\n",
    "    \n",
    "    if 'Vowels' in task_dfs:\n",
    "        df_vowels = task_dfs['Vowels']\n",
    "        print(f\"Vowels data: {len(df_vowels)} trials\")\n",
    "    \n",
    "    if 'CRM' in task_dfs:\n",
    "        df_crm = task_dfs['CRM']\n",
    "        print(f\"CRM data: {len(df_crm)} trials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5: Save the mega_df for future use\n",
    "if not mega_df.empty:\n",
    "    save_mega_df(mega_df, output_path='mega_df_all_subjects.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
