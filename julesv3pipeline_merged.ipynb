{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merged Analysis Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import os\n",
    "import re\n\n",
    "# Configure plotting style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [12, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRM Condition Mapping\n",
    "Edit the dictionary below to assign a condition (e.g., 'BM', 'CI', 'HA') to each CRM file number. This mapping will be used to automatically assign conditions during data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRM_CONDITION_MAP = {\n",
    "    0: 'BM',\n",
    "    1: 'BM',\n",
    "    2: 'BM',\n",
    "    3: 'CI',\n",
    "    4: 'CI',\n",
    "    5: 'CI',\n",
    "    6: 'HA',\n",
    "    7: 'HA',\n",
    "    8: 'HA',\n",
    "    9: 'UNKNOWN',\n",
    "    10: 'UNKNOWN'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing\n",
    "This section defines the functions to load and preprocess the data from the subject's directory. It prompts for a single directory path and then loads all relevant Vowel, Consonant, and CRM files. The CRM condition for each run is assigned based on the `CRM_CONDITION_MAP` dictionary defined above, streamlining the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper functions from v2.11.19 needed for loading ---\n",
    "def parse_crm_header(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            header = f.readline()\n",
    "        match = re.search(r'Talker (\\d+), Maskers (\\d+) and (\\d+)', header)\n",
    "        if match:\n",
    "            return int(match.group(1)), int(match.group(2)), int(match.group(3))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None, None, None\n",
    "\n",
    "def get_gender(talker_id):\n",
    "    if talker_id is None:\n",
    "        return 'Unknown'\n",
    "    return 'M' if talker_id <= 3 else 'F'\n",
    "\n",
    "def get_masker_type(talker, masker1, masker2):\n",
    "    if talker is None or masker1 is None or masker2 is None:\n",
    "        return 'unknown'\n",
    "    t_gen, m1_gen, m2_gen = get_gender(talker), get_gender(masker1), get_gender(masker2)\n",
    "    if t_gen == m1_gen == m2_gen:\n",
    "        return 'same'\n",
    "    if m1_gen == m2_gen and m1_gen != t_gen:\n",
    "        return 'different'\n",
    "    return 'mixed'\n",
    "\n",
    "def calculate_srt(df_run):\n",
    "    snr = df_run['snr'].values\n",
    "    correct = ((df_run['target_color'] == df_run['response_color']) & \\\n",
    "               (df_run['target_number'] == df_run['response_number'])).values\n",
    "    reversals = []\n",
    "    if len(correct) > 1:\n",
    "        prev = correct[0]\n",
    "        for i in range(1, len(correct)):\n",
    "            if correct[i] != prev:\n",
    "                reversals.append(snr[i])\n",
    "            prev = correct[i]\n",
    "    \n",
    "    if len(reversals) >= 5:\n",
    "        calc_revs = reversals[4:14] if len(reversals) >= 14 else reversals[4:]\n",
    "        return np.mean(calc_revs), np.std(calc_revs), len(reversals)\n",
    "    return np.nan, np.nan, len(reversals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Data Loading Function ---\n\n",
    "def load_all_data(base_path, crm_condition_map):\n",
    "    subject_id = os.path.basename(base_path)\n",
    "    print(f\"Loading data for {subject_id}...\")\n\n",
    "    # Initialize dataframes\n",
    "    df_vowel = pd.DataFrame()\n",
    "    df_consonant = pd.DataFrame()\n",
    "    df_crm = pd.DataFrame()\n",
    "    df_crm_summary = pd.DataFrame()\n\n",
    "    # 1. Load Vowels\n",
    "    vowel_cols = ['talker_id', 'vowel_id', 'response_id', 'score', 'rt']\n",
    "    vowel_map = {1:'AE', 2:'AH', 3:'AW', 4:'EH', 5:'IH', 6:'IY', 7:'OO', 8:'UH', 9:'UW'}\n",
    "    try:\n",
    "        df_v_bm = pd.read_csv(os.path.join(base_path, f'{subject_id}_vow9_BM_0.txt'), sep='\\s+', header=None, names=vowel_cols)\n",
    "        df_v_bm['condition'] = 'BM'\n",
    "        df_v_ci = pd.read_csv(os.path.join(base_path, f'{subject_id}_vow9_CI_0.txt'), sep='\\s+', header=None, names=vowel_cols)\n",
    "        df_v_ci['condition'] = 'CI'\n",
    "        df_vowel = pd.concat([df_v_bm, df_v_ci], ignore_index=True)\n",
    "        df_vowel['vowel_label'] = df_vowel['vowel_id'].map(vowel_map)\n",
    "        df_vowel['response_label'] = df_vowel['response_id'].map(vowel_map)\n",
    "        print(f\"Vowels loaded: {len(df_vowel)} trials\")\n",
    "    except Exception as e:\n",
    "        print(f\"Vowel load error: {e}\")\n\n",
    "    # 2. Load Consonants\n",
    "    cons_cols = ['talker_id', 'consonant_id', 'response_id', 'score', 'rt']\n",
    "    cons_map = {1:'#', 2:'_', 3:'b', 4:'d', 5:'f', 6:'g', 7:'k', 8:'m', 9:'n', 10:'%', 11:'p', 12:'s', 13:'t', 14:'v', 15:'z', 16:'$'}\n",
    "    try:\n",
    "        df_consonant = pd.read_csv(os.path.join(base_path, f'{subject_id}_cons_BM_n_0.out'), sep='\\s+', header=None, names=cons_cols)\n",
    "        df_consonant['consonant_label'] = df_consonant['consonant_id'].map(cons_map)\n",
    "        df_consonant['response_label'] = df_consonant['response_id'].map(cons_map)\n",
    "        print(f\"Consonants loaded: {len(df_consonant)} trials\")\n",
    "    except Exception as e:\n",
    "        print(f\"Consonant load error: {e}\")\n\n",
    "    # 3. Load CRM\n",
    "    print(\"Processing CRM files...\")\n",
    "    crm_cols = ['run', 'target_color', 'response_color', 'target_number', 'response_number', 'snr', 'rt']\n",
    "    crm_files = sorted([f for f in os.listdir(base_path) if '_crm_' in f and f.endswith('.txt')])\n",
    "    crm_data_frames = []\n",
    "    crm_summary_list = []\n\n",
    "    for f in crm_files:\n",
    "        try:\n",
    "            run_number = int(re.search(r'_crm_(\\d+)\\.txt', f).group(1))\n",
    "            condition = crm_condition_map.get(run_number, 'Unknown')\n\n",
    "            fpath = os.path.join(base_path, f)\n",
    "            talker, m1, m2 = parse_crm_header(fpath)\n",
    "            masker_type = get_masker_type(talker, m1, m2)\n\n",
    "            df_temp = pd.read_csv(fpath, sep='\\s+', header=None, skiprows=2, names=crm_cols, on_bad_lines='skip')\n",
    "            df_temp = df_temp[pd.to_numeric(df_temp['run'], errors='coerce').notna()].astype(float)\n\n",
    "            srt, sd, revs = calculate_srt(df_temp)\n\n",
    "            df_temp['filename'] = f\n",
    "            df_temp['condition'] = condition\n",
    "            df_temp['masker_type'] = masker_type\n",
    "            crm_data_frames.append(df_temp)\n\n",
    "            crm_summary_list.append({\n",
    "                'filename': f, 'condition': condition, 'masker_type': masker_type,\n",
    "                'talker_gender': get_gender(talker), 'srt': srt, 'sd': sd, 'reversals': revs\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"    - Could not process {f}: {e}\")\n\n",
    "    if crm_data_frames:\n",
    "        df_crm = pd.concat(crm_data_frames, ignore_index=True)\n",
    "        df_crm_summary = pd.DataFrame(crm_summary_list)\n",
    "        print(f\"CRM loaded: {len(crm_data_frames)} runs processed\")\n\n",
    "    return df_vowel, df_consonant, df_crm, df_crm_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Execute Data Loading ---\n",
    "data_path = input(\"Enter the directory path for the subject's data: \").strip()\n",
    "if os.path.isdir(data_path):\n",
    "    df_vowel, df_consonant, df_crm, df_crm_summary = load_all_data(data_path, CRM_CONDITION_MAP)\n",
    "else:\n",
    "    print(f\"Error: Directory not found at {data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vowel Recognition Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology: Vowel Confusion Matrix\n",
    "A confusion matrix is a powerful tool for analyzing classification performance. In this context:\n",
    "- **Rows** represent the **actual vowel** (the target phoneme).\n",
    "- **Columns** represent the **vowel perceived** by the listener (the response).\n",
    "- The **diagonal elements** (from top-left to bottom-right) show the number or percentage of **correctly identified vowels**.\n",
    "- **Off-diagonal elements** reveal specific error patterns. For example, a high value in the 'AH' row and 'AW' column indicates that the listener frequently mistakes 'AH' for 'AW'.\n",
    "We will generate two matrices: one with the raw counts of responses and another normalized to show probabilities, which helps in identifying systematic confusion patterns independent of the number of trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_vowel' in locals() and not df_vowel.empty:\n",
    "    # --- Overall Accuracy ---\n",
    "    overall_vowel_accuracy = df_vowel['score'].mean() * 100\n",
    "    print(f\"Overall Vowel Accuracy: {overall_vowel_accuracy:.2f}%\\n\\n\\n\")\n\n",
    "    # --- Confusion Matrix Generation ---\n",
    "    vowel_labels_sorted = sorted(df_vowel['vowel_label'].dropna().unique())\n",
    "    cm_counts = pd.crosstab(df_vowel['vowel_label'], df_vowel['response_label'], rownames=['Target'], colnames=['Response']).reindex(index=vowel_labels_sorted, columns=vowel_labels_sorted, fill_value=0)\n",
    "    cm_prob = cm_counts.div(cm_counts.sum(axis=1), axis=0).fillna(0)\n\n",
    "    # --- Visualization ---\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n\n",
    "    # Raw Counts Heatmap\n",
    "    sns.heatmap(cm_counts, annot=True, fmt='d', cmap='viridis', ax=axes[0], linewidths=.5)\n",
    "    axes[0].set_title('Vowel Confusion Matrix (Raw Counts)', fontsize=14)\n",
    "    axes[0].set_xlabel('Response', fontsize=12)\n",
    "    axes[0].set_ylabel('Target', fontsize=12)\n\n",
    "    # Probability Heatmap\n",
    "    sns.heatmap(cm_prob, annot=True, fmt='.2f', cmap='rocket_r', ax=axes[1], linewidths=.5)\n",
    "    axes[1].set_title('Vowel Confusion Matrix (Probabilities)', fontsize=14)\n",
    "    axes[1].set_xlabel('Response', fontsize=12)\n",
    "    axes[1].set_ylabel('Target', fontsize=12)\n\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Vowel data not loaded. Skipping analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Comparison: Vowel Accuracy by Condition\n",
    "To determine if there is a statistically significant difference in vowel recognition performance between the Bimodal (BM) and Cochlear Implant (CI) conditions, we use an independent samples t-test. This test is appropriate for comparing the means of two independent groups.\n\n",
    "**Rationale:**\n",
    "- **Null Hypothesis (H0):** There is no difference in the mean accuracy scores between the BM and CI groups.\n",
    "- **Alternative Hypothesis (H1):** There is a difference in the mean accuracy scores.\n",
    "- **Significance Level (Î±):** We will use a standard alpha of 0.05. If the p-value is less than 0.05, we reject the null hypothesis and conclude that the difference in performance is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_vowel' in locals() and not df_vowel.empty:\n",
    "    bm_scores = df_vowel[df_vowel['condition'] == 'BM']['score']\n",
    "    ci_scores = df_vowel[df_vowel['condition'] == 'CI']['score']\n\n",
    "    if not bm_scores.empty and not ci_scores.empty:\n",
    "        # --- Statistical Test ---\n",
    "        ttest_res = stats.ttest_ind(bm_scores, ci_scores, equal_var=False)  # Welch's t-test for unequal variances\n",
    "        print(f\"--- T-test Results: Vowel Accuracy (BM vs CI) ---\")\n",
    "        print(f\"BM Mean Accuracy: {bm_scores.mean() * 100:.2f}% (SD={bm_scores.std():.2f})\")\n",
    "        print(f\"CI Mean Accuracy: {ci_scores.mean() * 100:.2f}% (SD={ci_scores.std():.2f})\")\n",
    "        print(f\"T-statistic: {ttest_res.statistic:.3f}\")\n",
    "        print(f\"P-value: {ttest_res.pvalue:.3f}\")\n\n",
    "        if ttest_res.pvalue < 0.05:\n",
    "            print(\"Conclusion: The difference in vowel accuracy between BM and CI conditions is statistically significant.\")\n",
    "        else:\n",
    "            print(\"Conclusion: There is no statistically significant difference in vowel accuracy between the conditions.\")\n",
    "else:\n",
    "    print(\"Cannot perform statistical test: insufficient vowel data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Consonant Recognition Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology: Phonetic Feature Analysis\n",
    "Beyond simple accuracy, analyzing consonant confusions by phonetic features provides deeper insight into a listener's perceptual difficulties. This approach, similar to the principles outlined by Miller and Nicely (1955), categorizes phonemes based on core articulatory features:\n",
    "- **Voicing:** Whether the vocal cords vibrate during articulation (e.g., /b/ is voiced, /p/ is voiceless).\n",
    "- **Place of Articulation:** Where in the vocal tract the constriction occurs (e.g., bilabial for /p/, alveolar for /t/).\n",
    "- **Manner of Articulation:** How the sound is produced (e.g., stop/plosive for /t/, fricative for /s/).\n\n",
    "By mapping both the target and response phonemes to these features, we can calculate the **Information Transfer** (or feature transmission rate). This metric quantifies how well a listener preserves a specific feature, even if the phoneme itself is misidentified. For example, a high voicing score, despite low overall accuracy, suggests the listener can correctly distinguish voiced from voiceless sounds, but may be struggling with place or manner cues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_consonant' in locals() and not df_consonant.empty:\n",
    "    # --- Phonetic Feature Map ---\n",
    "    # 1=Voiced, 0=Voiceless; Place: 1=Bilabial, 0=Alveolar/Other; Manner: 0=Stop, 1=Nasal, 2=Fricative, 3=Affricate\n",
    "    feature_map = {\n",
    "        'b': (1, 1, 0), 'd': (1, 0, 0), 'g': (1, 0, 0),\n",
    "        'p': (0, 1, 0), 't': (0, 0, 0), 'k': (0, 0, 0),\n",
    "        'm': (1, 1, 1), 'n': (1, 0, 1),\n",
    "        'f': (0, 1, 2), 'v': (1, 1, 2), 's': (0, 0, 2), 'z': (1, 0, 2),\n",
    "        '#': (0, 0, 2), '_': (1, 0, 2),  # Sh, Zh\n",
    "        '%': (0, 0, 3), '$': (1, 0, 3)   # Ch, J\n",
    "    }\n\n",
    "    def calculate_information_transfer(df, label_col, resp_col, feat_map):\n",
    "        valid_df = df[df[label_col].isin(feat_map.keys()) & df[resp_col].isin(feat_map.keys())].copy()\n",
    "        if valid_df.empty:\n",
    "            return None\n\n",
    "        features = ['Voicing', 'Place', 'Manner']\n",
    "        results = {}\n\n",
    "        for i, feature in enumerate(features):\n",
    "            target_feature = valid_df[label_col].apply(lambda x: feat_map[x][i])\n",
    "            response_feature = valid_df[resp_col].apply(lambda x: feat_map[x][i])\n",
    "            accuracy = (target_feature == response_feature).mean() * 100\n",
    "            results[feature] = accuracy\n",
    "        return pd.Series(results)\n\n",
    "    # --- Analysis ---\n",
    "    feature_transfer_results = calculate_information_transfer(df_consonant, 'consonant_label', 'response_label', feature_map)\n\n",
    "    print(\"--- Phonetic Feature Transmission Rates ---\")\n",
    "    if feature_transfer_results is not None:\n",
    "        print(feature_transfer_results.round(2))\n",
    "        # --- Visualization ---\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.barplot(x=feature_transfer_results.index, y=feature_transfer_results.values, palette='colorblind')\n",
    "        plt.title('Consonant Feature Transmission', fontsize=14)\n",
    "        plt.ylabel('% Correct Transmission', fontsize=12)\n",
    "        plt.ylim(0, 100)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Could not calculate feature transfer (no valid consonant pairs found).\")\n",
    "else:\n",
    "    print(\"Consonant data not loaded. Skipping feature analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_consonant' in locals() and not df_consonant.empty:\n",
    "    # --- Overall Accuracy ---\n",
    "    overall_consonant_accuracy = df_consonant['score'].mean() * 100\n",
    "    print(f\"\\n--- Consonant Confusion Matrix Analysis ---\")\n",
    "    print(f\"Overall Consonant Accuracy: {overall_consonant_accuracy:.2f}%\\n\\n\\n\")\n\n",
    "    # --- Confusion Matrix Generation ---\n",
    "    consonant_labels_sorted = sorted(df_consonant['consonant_label'].dropna().unique())\n",
    "    cm_counts_cons = pd.crosstab(df_consonant['consonant_label'], df_consonant['response_label'], rownames=['Target'], colnames=['Response']).reindex(index=consonant_labels_sorted, columns=consonant_labels_sorted, fill_value=0)\n",
    "    cm_prob_cons = cm_counts_cons.div(cm_counts_cons.sum(axis=1), axis=0).fillna(0)\n\n",
    "    # --- Visualization ---\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n\n",
    "    # Raw Counts Heatmap\n",
    "    sns.heatmap(cm_counts_cons, annot=True, fmt='d', cmap='viridis', ax=axes[0], linewidths=.5)\n",
    "    axes[0].set_title('Consonant Confusion Matrix (Raw Counts)', fontsize=14)\n",
    "    axes[0].set_xlabel('Response', fontsize=12)\n",
    "    axes[0].set_ylabel('Target', fontsize=12)\n\n",
    "    # Probability Heatmap\n",
    "    sns.heatmap(cm_prob_cons, annot=True, fmt='.2f', cmap='rocket_r', ax=axes[1], linewidths=.5)\n",
    "    axes[1].set_title('Consonant Confusion Matrix (Probabilities)', fontsize=14)\n",
    "    axes[1].set_xlabel('Response', fontsize=12)\n",
    "    axes[1].set_ylabel('Target', fontsize=12)\n\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Consonant data not loaded. Skipping analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CRM Speech Reception Threshold (SRT) Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology: Speech Reception Threshold (SRT)\n",
    "The SRT represents the Signal-to-Noise Ratio (SNR) at which a listener can correctly identify 50% of the speech material. In this adaptive staircase procedure:\n",
    "- The SNR is adjusted based on the listener's response: it decreases after a correct response (making the task harder) and increases after an incorrect one (making it easier).\n",
    "- A **reversal** occurs when the direction of this change flips (e.g., from decreasing to increasing).\n",
    "- To calculate the SRT for a given run, we average the SNR values of the reversals, typically excluding the first few to allow the staircase to converge. Following the MATLAB script's logic, we will average reversals 5 through 14.\n\n",
    "Lower SRT values indicate better performance, as the listener can understand speech at more adverse SNR levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_crm_summary' in locals() and not df_crm_summary.empty:\n",
    "    # --- Granular Violin Plots ---\n",
    "    print(\"--- Granular SRT Analysis ---\")\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12), dpi=100)\n",
    "    axes = axes.flatten()\n\n",
    "    # Plot 1: Global SRT Distribution\n",
    "    sns.violinplot(y=df_crm_summary['srt'], ax=axes[0], color='skyblue', inner='quartile')\n",
    "    sns.stripplot(y=df_crm_summary['srt'], ax=axes[0], color='darkblue', jitter=0.1, size=8, edgecolor='w', linewidth=1)\n",
    "    axes[0].set_title('Global SRT Distribution', fontsize=14)\n",
    "    axes[0].set_ylabel('SRT (dB)', fontsize=12)\n\n",
    "    # Plot 2: SRT by Condition\n",
    "    sns.violinplot(x='condition', y='srt', data=df_crm_summary, ax=axes[1], inner='quartile', palette='pastel')\n",
    "    sns.stripplot(x='condition', y='srt', data=df_crm_summary, ax=axes[1], color='black', jitter=0.1, size=6)\n",
    "    axes[1].set_title('SRT by Condition', fontsize=14)\n",
    "    axes[1].set_xlabel('Condition', fontsize=12)\n",
    "    axes[1].set_ylabel('SRT (dB)', fontsize=12)\n\n",
    "    # Plot 3: SRT by Masker Type and Talker Gender\n",
    "    sns.violinplot(x='masker_type', y='srt', hue='talker_gender', data=df_crm_summary, ax=axes[2], inner='quartile', split=True, palette='muted')\n",
    "    sns.stripplot(x='masker_type', y='srt', hue='talker_gender', data=df_crm_summary, ax=axes[2], dodge=True, jitter=0.1, size=6, edgecolor='w', linewidth=1)\n",
    "    axes[2].set_title('SRT by Masker Type & Talker Gender', fontsize=14)\n",
    "    axes[2].set_xlabel('Masker Type', fontsize=12)\n",
    "    axes[2].set_ylabel('SRT (dB)', fontsize=12)\n\n",
    "    # Plot 4: SRT by Condition and Masker Type\n",
    "    sns.violinplot(x='condition', y='srt', hue='masker_type', data=df_crm_summary, ax=axes[3], inner='quartile', palette='coolwarm')\n",
    "    sns.stripplot(x='condition', y='srt', hue='masker_type', data=df_crm_summary, ax=axes[3], dodge=True, jitter=0.1, size=6, edgecolor='w', linewidth=1)\n",
    "    axes[3].set_title('SRT by Condition & Masker Type', fontsize=14)\n",
    "    axes[3].set_xlabel('Condition', fontsize=12)\n",
    "    axes[3].set_ylabel('SRT (dB)', fontsize=12)\n\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Faceted plot for the most granular view\n",
    "    g = sns.catplot(x='masker_type', y='srt', hue='talker_gender', col='condition', data=df_crm_summary, kind='violin', inner='quartile', split=True, palette='husl', height=5, aspect=0.9, legend_out=True)\n",
    "    g.map(sns.stripplot, 'masker_type', 'srt', 'talker_gender', dodge=True, jitter=0.1, size=5, edgecolor='black', linewidth=1)\n",
    "    g.fig.suptitle('SRT Stratified by All Groups', y=1.03, fontsize=16)\n",
    "    g.set_axis_labels('Masker Type', 'SRT (dB)')\n",
    "    g.add_legend(title='Talker Gender')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"CRM data not available for SRT analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Comparison: ANOVA on SRTs\n",
    "To assess the impact of different factors on speech recognition, we perform a two-way ANOVA (Analysis of Variance). This test allows us to examine the main effects of `condition` and `masker_type` on SRT, as well as their interaction.\n\n",
    "**Rationale:**\n",
    "- **Main Effect of Condition:** Does the listening condition (BM, CI, HA) significantly affect SRT?\n",
    "- **Main Effect of Masker Type:** Does the masker gender (same vs. different) significantly affect SRT?\n",
    "- **Interaction Effect:** Does the effect of masker gender depend on the listening condition? (e.g., is the benefit of different-gender maskers larger in one condition than another?).\n\n",
    "A significant p-value (p < 0.05) for any of these factors suggests it has a meaningful impact on performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_crm_summary' in locals() and len(df_crm_summary['condition'].unique()) > 1:\n",
    "    print(\"--- Two-Way ANOVA Results: SRT ~ Condition * Masker Type ---\")\n",
    "    model = ols('srt ~ C(condition) * C(masker_type)', data=df_crm_summary.dropna()).fit()\n",
    "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "    print(anova_table)\n\n",
    "    # Interpretation\n",
    "    p_condition = anova_table['PR(>F)'][0]\n",
    "    p_masker = anova_table['PR(>F)'][1]\n",
    "    p_interaction = anova_table.get('PR(>F)', [np.nan, np.nan, np.nan, np.nan])[2]  # Handle case with no interaction term\n\n",
    "    print(\"\\n--- ANOVA Interpretation ---\")\n",
    "    if p_condition < 0.05:\n",
    "        print(f\"- The main effect of 'condition' is significant (p={p_condition:.3f}). SRT performance differs across conditions.\")\n",
    "    else:\n",
    "        print(f\"- The main effect of 'condition' is not significant (p={p_condition:.3f}).\")\n\n",
    "    if p_masker < 0.05:\n",
    "        print(f\"- The main effect of 'masker_type' is significant (p={p_masker:.3f}). Same vs. different-gender maskers yield different SRTs.\")\n",
    "    else:\n",
    "        print(f\"- The main effect of 'masker_type' is not significant (p={p_masker:.3f}).\")\n\n",
    "    if p_interaction < 0.05:\n",
    "        print(f\"- The interaction effect is significant (p={p_interaction:.3f}). The benefit of masker gender depends on the listening condition.\")\n",
    "    else:\n",
    "        print(f\"- The interaction effect is not significant (p={p_interaction:.3f}).\")\n",
    "else:\n",
    "    print(\"ANOVA not performed: requires at least two conditions with valid SRT data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced CRM and Temporal Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced CRM Error Analysis\n",
    "This analysis breaks down CRM trial outcomes into four categories to understand the nature of listener errors:\n",
    "- **Correct:** Both color and number were identified correctly.\n",
    "- **Color Error:** The number was correct, but the color was wrong.\n",
    "- **Number Error:** The color was correct, but the number was wrong.\n",
    "- **Both Error:** Both color and number were incorrect.\n\n",
    "By stratifying these error types by condition, masker type, and talker gender, we can identify if specific listening situations lead to particular kinds of perceptual errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_crm' in locals() and not df_crm.empty:\n",
    "    # --- Error Classification ---\n",
    "    def classify_crm_error(row):\n",
    "        color_ok = row['target_color'] == row['response_color']\n",
    "        number_ok = row['target_number'] == row['response_number']\n",
    "        if color_ok and number_ok: return 'Correct'\n",
    "        if not color_ok and number_ok: return 'Color Error'\n",
    "        if color_ok and not number_ok: return 'Number Error'\n",
    "        return 'Both Error'\n\n",
    "    df_crm['error_type'] = df_crm.apply(classify_crm_error, axis=1)\n",
    "    df_crm['talker_gender'] = df_crm['filename'].apply(lambda f: get_gender(parse_crm_header(os.path.join(data_path, f))[0]))\n\n",
    "    # --- Visualization Panels ---\n",
    "    print(\"--- CRM Error Analysis by Group ---\")\n",
    "    error_order = ['Correct', 'Color Error', 'Number Error', 'Both Error']\n",
    "    palette = {'Correct': 'green', 'Color Error': 'blue', 'Number Error': 'orange', 'Both Error': 'red'}\n\n",
    "    # Faceted bar charts\n",
    "    g = sns.catplot(x='condition', hue='error_type', col='masker_type', row='talker_gender',\n",
    "                    data=df_crm, kind='count', hue_order=error_order, palette=palette,\n",
    "                    height=5, aspect=1.2, legend=False)\n\n",
    "    g.fig.suptitle('CRM Error Type Distribution by All Groups', y=1.03, fontsize=16)\n",
    "    g.set_axis_labels('Condition', 'Number of Trials')\n",
    "    g.set_titles('Masker: {col_name} | Talker: {row_name}')\n",
    "    g.add_legend(title='Error Type')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"CRM data not available for error analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Trend Analysis\n",
    "This analysis investigates whether the listener's performance changes over the course of the experiment. An upward trend in accuracy (or downward trend in SRT) might suggest a learning effect, while a downward trend could indicate fatigue.\n\n",
    "We will plot the score for each trial in sequential order and overlay a rolling average to smooth out noise and make the underlying trend more visible. A linear regression line is also fitted to provide a simple quantitative measure of the trend's direction and magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_temporal_trend(df, metric_col, title, ax):\n",
    "    df_seq = df.reset_index(drop=True).reset_index().rename(columns={'index': 'trial_sequence'})\n",
    "    window_size = min(20, len(df_seq) // 2)\n",
    "    if window_size > 0:\n",
    "        df_seq['rolling_avg'] = df_seq[metric_col].rolling(window=window_size).mean()\n\n",
    "    # Plotting\n",
    "    sns.lineplot(x='trial_sequence', y='rolling_avg', data=df_seq, ax=ax, color='red', label=f'{window_size}-Trial Rolling Avg')\n",
    "    sns.regplot(x='trial_sequence', y=metric_col, data=df_seq, ax=ax, scatter_kws={'alpha':0.2, 's':15}, line_kws={'color':'blue', 'linestyle':'--'}, label='Linear Trend')\n",
    "    ax.set_title(title, fontsize=12)\n",
    "    ax.set_xlabel('Trial Sequence', fontsize=10)\n",
    "    ax.set_ylabel(metric_col.replace('_', ' ').title(), fontsize=10)\n",
    "    ax.legend()\n\n",
    "if 'df_vowel' in locals() and not df_vowel.empty:\n",
    "    print(\"\\n--- Temporal Trend Analysis: Vowel Accuracy ---\")\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(14, 5))\n",
    "    plot_temporal_trend(df_vowel, 'score', 'Overall Vowel Accuracy Trend', axes)\n",
    "    plt.show()\n\n",
    "    # Stratified by condition\n",
    "    g = sns.lmplot(x='trial_sequence', y='score', data=df_vowel.reset_index(drop=True).reset_index().rename(columns={'index': 'trial_sequence'}),\n",
    "                   col='condition', height=5, aspect=1.2, scatter_kws={'alpha':0.2, 's':15})\n",
    "    g.fig.suptitle('Vowel Accuracy Trend by Condition', y=1.03, fontsize=16)\n",
    "    g.set_axis_labels('Trial Sequence', 'Score')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Vowel data not available for temporal analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}