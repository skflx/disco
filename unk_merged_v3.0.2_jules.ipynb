{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reiss Lab Data Analysis Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "Import the necessary libraries for data manipulation, analysis, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Configure plotting style\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing\n",
    "\n",
    "Load the raw data files for the vowel, consonant, and CRM experiments. We will also perform initial preprocessing, such as adding column names and mapping identifiers to human-readable labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the directory path containing your data files:  /Users/samipkafle/Downloads/reiss_lab_analysis/data/Data/CI148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for subject: CI148\n",
      "Data directory: /Users/samipkafle/Downloads/reiss_lab_analysis/data/Data/CI148\n",
      "\n",
      "Files found in directory:\n",
      "  .DS_Store\n",
      "  CI148_cons_BM_n_0.out\n",
      "  CI148_consch.all\n",
      "  CI148_crm_0.txt\n",
      "  CI148_crm_1.txt\n",
      "  CI148_crm_10.txt\n",
      "  CI148_crm_2.txt\n",
      "  CI148_crm_3.txt\n",
      "  CI148_crm_4.txt\n",
      "  CI148_crm_5.txt\n",
      "  CI148_crm_6.txt\n",
      "  CI148_crm_7.txt\n",
      "  CI148_crm_8.txt\n",
      "  CI148_crm_9.txt\n",
      "  CI148_vow9_BM_0.txt\n",
      "  CI148_vow9_CI_0.txt\n",
      "  CI148_vowch.all\n",
      "  test_vowch.all\n"
     ]
    }
   ],
   "source": [
    "# Prompt user to input the directory path containing the data files\n",
    "base_path = input(\"Enter the directory path containing your data files: \").strip()\n",
    "\n",
    "# Validate that the path exists\n",
    "if not os.path.isdir(base_path):\n",
    "    raise FileNotFoundError(f\"Directory not found: {base_path}\")\n",
    "\n",
    "# Extract subject ID from the directory name (assumes format like 'CI148')\n",
    "subject_id = os.path.basename(base_path)\n",
    "print(f\"Processing data for subject: {subject_id}\")\n",
    "print(f\"Data directory: {base_path}\")\n",
    "\n",
    "# --- File Paths ---\n",
    "vowel_bm_path = os.path.join(base_path, f'{subject_id}_vow9_BM_0.txt')\n",
    "vowel_ci_path = os.path.join(base_path, f'{subject_id}_vow9_CI_0.txt')\n",
    "consonant_path = os.path.join(base_path, f'{subject_id}_cons_BM_n_0.out')\n",
    "\n",
    "# For CRM, we'll start by loading one file and create a list for scalability\n",
    "crm_files = [os.path.join(base_path, f'{subject_id}_crm_{i}.txt') for i in range(11)]\n",
    "\n",
    "# Show available files in directory\n",
    "print(f\"\\nFiles found in directory:\")\n",
    "for f in sorted(os.listdir(base_path)):\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Vowel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vowel data loaded and preprocessed:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 360 entries, 0 to 359\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   talker_id       360 non-null    int64  \n",
      " 1   vowel_id        360 non-null    int64  \n",
      " 2   response_id     360 non-null    int64  \n",
      " 3   score           360 non-null    int64  \n",
      " 4   rt              360 non-null    float64\n",
      " 5   condition       360 non-null    object \n",
      " 6   vowel_label     360 non-null    object \n",
      " 7   response_label  360 non-null    object \n",
      "dtypes: float64(1), int64(4), object(3)\n",
      "memory usage: 22.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talker_id</th>\n",
       "      <th>vowel_id</th>\n",
       "      <th>response_id</th>\n",
       "      <th>score</th>\n",
       "      <th>rt</th>\n",
       "      <th>condition</th>\n",
       "      <th>vowel_label</th>\n",
       "      <th>response_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8965</td>\n",
       "      <td>BM</td>\n",
       "      <td>OO</td>\n",
       "      <td>OO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5742</td>\n",
       "      <td>BM</td>\n",
       "      <td>OO</td>\n",
       "      <td>OO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7898</td>\n",
       "      <td>BM</td>\n",
       "      <td>AW</td>\n",
       "      <td>AH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6783</td>\n",
       "      <td>BM</td>\n",
       "      <td>UH</td>\n",
       "      <td>UH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1938</td>\n",
       "      <td>BM</td>\n",
       "      <td>OO</td>\n",
       "      <td>OO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   talker_id  vowel_id  response_id  score      rt condition vowel_label  \\\n",
       "0         16         7            7      1  1.8965        BM          OO   \n",
       "1          8         7            7      1  3.5742        BM          OO   \n",
       "2          9         3            2      0  1.7898        BM          AW   \n",
       "3          4         8            8      1  1.6783        BM          UH   \n",
       "4          4         7            7      1  2.1938        BM          OO   \n",
       "\n",
       "  response_label  \n",
       "0             OO  \n",
       "1             OO  \n",
       "2             AH  \n",
       "3             UH  \n",
       "4             OO  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowel_cols = ['talker_id', 'vowel_id', 'response_id', 'score', 'rt']\n",
    "\n",
    "# Load individual vowel files\n",
    "df_vowel_bm = pd.read_csv(vowel_bm_path, sep='\\\\s+', header=None, names=vowel_cols)\n",
    "df_vowel_ci = pd.read_csv(vowel_ci_path, sep='\\\\s+', header=None, names=vowel_cols)\n",
    "\n",
    "# Add a 'condition' column to distinguish them\n",
    "df_vowel_bm['condition'] = 'BM' # Bimodal\n",
    "df_vowel_ci['condition'] = 'CI' # Cochlear Implant\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "df_vowel = pd.concat([df_vowel_bm, df_vowel_ci], ignore_index=True)\n",
    "\n",
    "# Define vowel labels from documentation\n",
    "vowel_map = {\n",
    "    1: 'AE', 2: 'AH', 3: 'AW', 4: 'EH', 5: 'IH',\n",
    "    6: 'IY', 7: 'OO', 8: 'UH', 9: 'UW'\n",
    "}\n",
    "\n",
    "# Map IDs to human-readable labels\n",
    "df_vowel['vowel_label'] = df_vowel['vowel_id'].map(vowel_map)\n",
    "df_vowel['response_label'] = df_vowel['response_id'].map(vowel_map)\n",
    "\n",
    "print(\"Vowel data loaded and preprocessed:\")\n",
    "df_vowel.info()\n",
    "df_vowel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Consonant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consonant data loaded and preprocessed:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64 entries, 0 to 63\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   talker_id        64 non-null     int64  \n",
      " 1   consonant_id     64 non-null     int64  \n",
      " 2   response_id      64 non-null     int64  \n",
      " 3   score            64 non-null     int64  \n",
      " 4   rt               64 non-null     float64\n",
      " 5   consonant_label  64 non-null     object \n",
      " 6   response_label   64 non-null     object \n",
      "dtypes: float64(1), int64(4), object(2)\n",
      "memory usage: 3.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talker_id</th>\n",
       "      <th>consonant_id</th>\n",
       "      <th>response_id</th>\n",
       "      <th>score</th>\n",
       "      <th>rt</th>\n",
       "      <th>consonant_label</th>\n",
       "      <th>response_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.8202</td>\n",
       "      <td>%</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.4925</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6630</td>\n",
       "      <td>k</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8300</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1810</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   talker_id  consonant_id  response_id  score       rt consonant_label  \\\n",
       "0          4            10            1      0  20.8202               %   \n",
       "1          3             2            2      1   3.4925               _   \n",
       "2          4             7            7      1   1.6630               k   \n",
       "3          3             9            9      1   1.8300               n   \n",
       "4          2             8            8      1   2.1810               m   \n",
       "\n",
       "  response_label  \n",
       "0              #  \n",
       "1              _  \n",
       "2              k  \n",
       "3              n  \n",
       "4              m  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consonant_cols = ['talker_id', 'consonant_id', 'response_id', 'score', 'rt']\n",
    "\n",
    "# Load the consonant file\n",
    "df_consonant = pd.read_csv(consonant_path, sep='\\\\s+', header=None, names=consonant_cols)\n",
    "\n",
    "# Define consonant labels from documentation\n",
    "consonant_map = {\n",
    "    1: '#', 2: '_', 3: 'b', 4: 'd', 5: 'f', 6: 'g', 7: 'k',\n",
    "    8: 'm', 9: 'n', 10: '%', 11: 'p', 12: 's', 13: 't',\n",
    "    14: 'v', 15: 'z', 16: '$'\n",
    "}\n",
    "\n",
    "# Map IDs to human-readable labels\n",
    "df_consonant['consonant_label'] = df_consonant['consonant_id'].map(consonant_map)\n",
    "df_consonant['response_label'] = df_consonant['response_id'].map(consonant_map)\n",
    "\n",
    "print(\"Consonant data loaded and preprocessed:\")\n",
    "df_consonant.info()\n",
    "df_consonant.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 CRM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 CRM files:\n",
      "\n",
      "  CI148_crm_0.txt\n",
      "  CI148_crm_1.txt\n",
      "  CI148_crm_10.txt\n",
      "  CI148_crm_2.txt\n",
      "  CI148_crm_3.txt\n",
      "  CI148_crm_4.txt\n",
      "  CI148_crm_5.txt\n",
      "  CI148_crm_6.txt\n",
      "  CI148_crm_7.txt\n",
      "  CI148_crm_8.txt\n",
      "  CI148_crm_9.txt\n",
      "\n",
      "Please assign a condition (e.g., BM, CI, HA) to the CRM files.\n",
      "Enter assignments as a dictionary: {'CONDITION': 'file_numbers'}\n",
      "Example: {'BM': '1,2,3', 'CI': '4,5,6'}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter assignments:  {'BM': '1,2,3,8', 'CI': '4, 6, 10', 'HA': '5,7,9'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 96\u001b[0m\n\u001b[1;32m     94\u001b[0m filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, filename)\n\u001b[1;32m     95\u001b[0m talker, masker1, masker2 \u001b[38;5;241m=\u001b[39m parse_crm_header(filepath)\n\u001b[0;32m---> 96\u001b[0m masker_type \u001b[38;5;241m=\u001b[39m get_masker_type(talker, masker1, masker2)\n\u001b[1;32m     98\u001b[0m file_num_match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_crm_(\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124md+)\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, filename)\n\u001b[1;32m     99\u001b[0m condition \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNKNOWN\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m, in \u001b[0;36mget_masker_type\u001b[0;34m(talker, masker1, masker2)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_masker_type\u001b[39m(talker, masker1, masker2):\n\u001b[1;32m     21\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Determine if maskers are same or different gender from target.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     target_gender \u001b[38;5;241m=\u001b[39m get_gender(talker)\n\u001b[1;32m     23\u001b[0m     masker1_gender \u001b[38;5;241m=\u001b[39m get_gender(masker1)\n\u001b[1;32m     24\u001b[0m     masker2_gender \u001b[38;5;241m=\u001b[39m get_gender(masker2)\n",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m, in \u001b[0;36mget_gender\u001b[0;34m(talker_id)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_gender\u001b[39m(talker_id):\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Talkers 0-3 are male, 4-7 are female.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m talker_id \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "\n",
    "def parse_crm_header(filepath):\n",
    "    \"\"\"Parse CRM file header to extract talker and masker info.\"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        header = f.readline()\n",
    "    match = re.search(r'Talker (\\\\d+), Maskers (\\\\d+) and (\\\\d+)', header)\n",
    "    if match:\n",
    "        talker = int(match.group(1))\n",
    "        masker1 = int(match.group(2))\n",
    "        masker2 = int(match.group(3))\n",
    "        return talker, masker1, masker2\n",
    "    return None, None, None\n",
    "\n",
    "def get_gender(talker_id):\n",
    "    \"\"\"Talkers 0-3 are male, 4-7 are female.\"\"\"\n",
    "    return 'M' if talker_id <= 3 else 'F'\n",
    "\n",
    "def get_masker_type(talker, masker1, masker2):\n",
    "    \"\"\"Determine if maskers are same or different gender from target.\"\"\"\n",
    "    target_gender = get_gender(talker)\n",
    "    masker1_gender = get_gender(masker1)\n",
    "    masker2_gender = get_gender(masker2)\n",
    "    if target_gender == masker1_gender == masker2_gender:\n",
    "        return 'same'\n",
    "    elif masker1_gender == masker2_gender and masker1_gender != target_gender:\n",
    "        return 'different'\n",
    "    else:\n",
    "        return 'mixed'\n",
    "\n",
    "def calculate_srt_from_trials(df_run):\n",
    "    \"\"\"\n",
    "    Calculate SRT using adaptive staircase reversal method.\n",
    "    Assumptions (matching MATLAB code):\n",
    "    - A trial is correct if BOTH color and number are correct.\n",
    "    - SRT = mean of reversals 5-14.\n",
    "    \"\"\"\n",
    "    snr_values = df_run['snr'].values\n",
    "    correct = (df_run['target_color'] == df_run['response_color']) & (df_run['target_number'] == df_run['response_number'])\n",
    "    \n",
    "    reversals = []\n",
    "    if len(correct) > 1:\n",
    "        prev_correct = correct.iloc[0]\n",
    "        for i in range(1, len(correct)):\n",
    "            if correct.iloc[i] != prev_correct:\n",
    "                reversals.append(snr_values[i])\n",
    "            prev_correct = correct.iloc[i]\n",
    "\n",
    "    if len(reversals) >= 14:\n",
    "        srt_reversals = reversals[4:14]\n",
    "        srt = np.mean(srt_reversals)\n",
    "        sd = np.std(srt_reversals, ddof=0)\n",
    "    elif len(reversals) >= 5:\n",
    "        srt_reversals = reversals[4:]\n",
    "        srt = np.mean(srt_reversals)\n",
    "        sd = np.std(srt_reversals, ddof=0)\n",
    "    else:\n",
    "        srt, sd = np.nan, np.nan\n",
    "    \n",
    "    return srt, sd, len(reversals)\n",
    "\n",
    "# --- CRM Data Loading ---\n",
    "crm_files_found = sorted([f for f in os.listdir(base_path) if '_crm_' in f and f.endswith('.txt')])\n",
    "print(f\"Found {len(crm_files_found)} CRM files:\\n\")\n",
    "for f in crm_files_found:\n",
    "    print(f\"  {f}\")\n",
    "\n",
    "print(\"\\nPlease assign a condition (e.g., BM, CI, HA) to the CRM files.\")\n",
    "print(\"Enter assignments as a dictionary: {'CONDITION': 'file_numbers'}\")\n",
    "print(\"Example: {'BM': '1,2,3', 'CI': '4,5,6'}\")\n",
    "assignments_str = input(\"Enter assignments: \").strip()\n",
    "\n",
    "try:\n",
    "    assignments = ast.literal_eval(assignments_str)\n",
    "except (ValueError, SyntaxError):\n",
    "    print(\"Invalid dictionary format. Please restart and try again.\")\n",
    "    assignments = {}\n",
    "\n",
    "file_to_condition = {}\n",
    "for condition, numbers_str in assignments.items():\n",
    "    try:\n",
    "        numbers = [int(n.strip()) for n in numbers_str.split(',')]\n",
    "        for num in numbers:\n",
    "            file_to_condition[num] = condition.strip().upper()\n",
    "    except ValueError:\n",
    "        print(f\"Warning: Could not parse numbers for condition '{condition}'. Please check formatting.\")\n",
    "\n",
    "crm_cols = ['run', 'target_color', 'response_color', 'target_number', 'response_number', 'snr', 'rt']\n",
    "crm_data_frames = []\n",
    "crm_summary = []\n",
    "\n",
    "for filename in crm_files_found:\n",
    "    filepath = os.path.join(base_path, filename)\n",
    "    talker, masker1, masker2 = parse_crm_header(filepath)\n",
    "    masker_type = get_masker_type(talker, masker1, masker2)\n",
    "\n",
    "    file_num_match = re.search(r'_crm_(\\\\d+)\\\\.txt', filename)\n",
    "    condition = 'UNKNOWN'\n",
    "    if file_num_match:\n",
    "        file_num = int(file_num_match.group(1))\n",
    "        condition = file_to_condition.get(file_num, 'UNKNOWN')\n",
    "\n",
    "    df_temp = pd.read_csv(filepath, sep='\\\\s+', header=None, skiprows=2, names=crm_cols, on_bad_lines='skip')\n",
    "    df_temp = df_temp[pd.to_numeric(df_temp['run'], errors='coerce').notna()].copy()\n",
    "    df_temp = df_temp.astype(dict.fromkeys(df_temp.columns[:5], int) | dict.fromkeys(df_temp.columns[5:], float))\n",
    "\n",
    "    srt, sd, n_reversals = calculate_srt_from_trials(df_temp)\n",
    "\n",
    "    df_temp['filename'] = filename\n",
    "    df_temp['condition'] = condition\n",
    "    df_temp['talker'] = talker\n",
    "    df_temp['masker_type'] = masker_type\n",
    "    crm_data_frames.append(df_temp)\n",
    "\n",
    "    crm_summary.append({\n",
    "        'filename': filename, 'condition': condition, 'talker': talker,\n",
    "        'talker_gender': get_gender(talker), 'masker_type': masker_type, 'n_trials': len(df_temp),\n",
    "        'n_reversals': n_reversals, 'srt': srt, 'sd': sd\n",
    "    })\n",
    "\n",
    "if crm_data_frames:\n",
    "    df_crm = pd.concat(crm_data_frames, ignore_index=True)\n",
    "    df_crm_summary = pd.DataFrame(crm_summary)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Total CRM files loaded: {len(crm_data_frames)}\")\n",
    "    print(f\"Total CRM trials: {len(df_crm)}\")\n",
    "else:\n",
    "    print(\"No CRM files were loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Vowel Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Accuracy\n",
    "vowel_accuracy = df_vowel['score'].mean() * 100\n",
    "print(f\"Overall Vowel Accuracy: {vowel_accuracy:.2f}%\\n\")\n",
    "\n",
    "# Confusion Matrix\n",
    "vowel_labels = [v for k, v in sorted(vowel_map.items())]\n",
    "vowel_cm_counts = pd.crosstab(df_vowel['vowel_label'], df_vowel['response_label'], rownames=['Target'], colnames=['Response'], margins=False, dropna=False).reindex(index=vowel_labels, columns=vowel_labels, fill_value=0)\n",
    "vowel_cm_probs = vowel_cm_counts.div(vowel_cm_counts.sum(axis=1), axis=0).fillna(0)\n",
    "print(\"Vowel Confusion Matrix (Probabilities):\")\n",
    "print(vowel_cm_probs)\n",
    "\n",
    "# Per-Vowel Accuracy\n",
    "per_vowel_accuracy = pd.DataFrame(np.diag(vowel_cm_probs) * 100, index=vowel_cm_probs.index, columns=['Accuracy'])\n",
    "print(\"\\nPer-Vowel Accuracy:\")\n",
    "print(per_vowel_accuracy)\n",
    "\n",
    "# By-Talker Accuracy\n",
    "vowel_talker_accuracy = df_vowel.groupby('talker_id')['score'].mean().reset_index()\n",
    "print(\"\\nBy-Talker Vowel Accuracy:\")\n",
    "print(vowel_talker_accuracy)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(vowel_cm_probs, annot=True, fmt='.2f', cmap='viridis')\n",
    "plt.title('Vowel Confusion Matrix')\n",
    "plt.savefig('vowel_confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=per_vowel_accuracy.index, y='Accuracy', data=per_vowel_accuracy)\n",
    "plt.title('Per-Vowel Accuracy')\n",
    "plt.savefig('per_vowel_accuracy.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='talker_id', y='score', data=vowel_talker_accuracy)\n",
    "plt.title('By-Talker Vowel Accuracy')\n",
    "plt.savefig('vowel_talker_accuracy.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_vowel['rt'], bins=20, kde=True)\n",
    "plt.title('Vowel Response Time Distribution')\n",
    "plt.savefig('vowel_rt_histogram.png')\n",
    "plt.show()\n",
    "\n",
    "# Save data\n",
    "vowel_cm_probs.to_csv('vowel_confusion_matrix.csv')\n",
    "per_vowel_accuracy.to_csv('per_vowel_accuracy.csv')\n",
    "vowel_talker_accuracy.to_csv('vowel_talker_accuracy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Consonant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Accuracy\n",
    "consonant_accuracy = df_consonant['score'].mean() * 100\n",
    "print(f\"Overall Consonant Accuracy: {consonant_accuracy:.2f}%\\n\")\n",
    "\n",
    "# Confusion Matrix\n",
    "consonant_labels = [v for k, v in sorted(consonant_map.items())]\n",
    "consonant_cm_counts = pd.crosstab(df_consonant['consonant_label'], df_consonant['response_label'], rownames=['Target'], colnames=['Response'], margins=False, dropna=False).reindex(index=consonant_labels, columns=consonant_labels, fill_value=0)\n",
    "consonant_cm_probs = consonant_cm_counts.div(consonant_cm_counts.sum(axis=1), axis=0).fillna(0)\n",
    "print(\"Consonant Confusion Matrix (Probabilities):\")\n",
    "print(consonant_cm_probs)\n",
    "\n",
    "# Per-Consonant Accuracy\n",
    "per_consonant_accuracy = pd.DataFrame(np.diag(consonant_cm_probs) * 100, index=consonant_cm_probs.index, columns=['Accuracy'])\n",
    "print(\"\\nPer-Consonant Accuracy:\")\n",
    "print(per_consonant_accuracy)\n",
    "\n",
    "# By-Talker Accuracy\n",
    "consonant_talker_accuracy = df_consonant.groupby('talker_id')['score'].mean().reset_index()\n",
    "print(\"\\nBy-Talker Consonant Accuracy:\")\n",
    "print(consonant_talker_accuracy)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(consonant_cm_probs, annot=True, fmt='.2f', cmap='viridis')\n",
    "plt.title('Consonant Confusion Matrix')\n",
    "plt.savefig('consonant_confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=per_consonant_accuracy.index, y='Accuracy', data=per_consonant_accuracy)\n",
    "plt.title('Per-Consonant Accuracy')\n",
    "plt.savefig('per_consonant_accuracy.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='talker_id', y='score', data=consonant_talker_accuracy)\n",
    "plt.title('By-Talker Consonant Accuracy')\n",
    "plt.savefig('consonant_talker_accuracy.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_consonant['rt'], bins=20, kde=True)\n",
    "plt.title('Consonant Response Time Distribution')\n",
    "plt.savefig('consonant_rt_histogram.png')\n",
    "plt.show()\n",
    "\n",
    "# Save data\n",
    "consonant_cm_probs.to_csv('consonant_confusion_matrix.csv')\n",
    "per_consonant_accuracy.to_csv('per_consonant_accuracy.csv')\n",
    "consonant_talker_accuracy.to_csv('consonant_talker_accuracy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 CRM Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display summary table\n",
    "print(\"CRM Summary Table:\")\n",
    "print(\"=\"*80)\n",
    "display_cols = ['filename', 'condition', 'talker_gender', 'masker_type', 'n_trials', 'srt', 'sd']\n",
    "print(df_crm_summary[display_cols].to_string(index=False))\n",
    "print()\n",
    "\n",
    "# Summary statistics by condition\n",
    "print(\"\\nSRT by Condition:\")\n",
    "print(\"-\"*40)\n",
    "condition_stats = df_crm_summary.groupby('condition').agg({\n",
    "    'srt': ['mean', 'std', 'count'],\n",
    "    'sd': 'mean'\n",
    "}).round(2)\n",
    "condition_stats.columns = ['Mean SRT (dB)', 'SRT SD', 'N runs', 'Mean within-run SD']\n",
    "print(condition_stats)\n",
    "print()\n",
    "\n",
    "# Summary statistics by masker type\n",
    "print(\"\\nSRT by Masker Type:\")\n",
    "print(\"-\"*40)\n",
    "masker_stats = df_crm_summary.groupby('masker_type').agg({\n",
    "    'srt': ['mean', 'std', 'count']\n",
    "}).round(2)\n",
    "masker_stats.columns = ['Mean SRT (dB)', 'SRT SD', 'N runs']\n",
    "print(masker_stats)\n",
    "print()\n",
    "\n",
    "# Summary by condition AND masker type (for VGRM-like analysis)\n",
    "print(\"\\nSRT by Condition × Masker Type:\")\n",
    "print(\"-\"*40)\n",
    "cross_stats = df_crm_summary.groupby(['condition', 'masker_type']).agg({\n",
    "    'srt': ['mean', 'std', 'count']\n",
    "}).round(2)\n",
    "cross_stats.columns = ['Mean SRT (dB)', 'SRT SD', 'N']\n",
    "print(cross_stats)\n",
    "print()\n",
    "\n",
    "# Calculate Voice-Gender Release from Masking (VGRM) if both conditions exist\n",
    "print(\"\\nVoice-Gender Release from Masking (VGRM):\")\n",
    "print(\"-\"*40)\n",
    "print(\"VGRM = SRT(same-gender) - SRT(different-gender)\")\n",
    "print(\"Positive values indicate benefit from different-gender maskers\\n\")\n",
    "\n",
    "for condition in df_crm_summary['condition'].unique():\n",
    "    cond_data = df_crm_summary[df_crm_summary['condition'] == condition]\n",
    "    same_srt = cond_data[cond_data['masker_type'] == 'same']['srt'].mean()\n",
    "    diff_srt = cond_data[cond_data['masker_type'] == 'different']['srt'].mean()\n",
    "    \n",
    "    if not np.isnan(same_srt) and not np.isnan(diff_srt):\n",
    "        vgrm = same_srt - diff_srt\n",
    "        print(f\"{condition}: VGRM = {vgrm:.2f} dB (same: {same_srt:.2f}, diff: {diff_srt:.2f})\")\n",
    "    else:\n",
    "        print(f\"{condition}: Insufficient data for VGRM calculation\")\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: SRT by condition\n",
    "sns.barplot(data=df_crm_summary, x='condition', y='srt', ax=axes[0], errorbar='sd')\n",
    "axes[0].set_xlabel('Condition')\n",
    "axes[0].set_ylabel('SRT (dB)')\n",
    "axes[0].set_title('SRT by Condition')\n",
    "axes[0].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Plot 2: SRT by masker type\n",
    "sns.barplot(data=df_crm_summary, x='masker_type', y='srt', ax=axes[1], errorbar='sd')\n",
    "axes[1].set_xlabel('Masker Type')\n",
    "axes[1].set_ylabel('SRT (dB)')\n",
    "axes[1].set_title('SRT by Masker Gender')\n",
    "axes[1].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Plot 3: SRT by condition and masker type\n",
    "sns.barplot(data=df_crm_summary, x='condition', y='srt', hue='masker_type', ax=axes[2], errorbar='sd')\n",
    "axes[2].set_xlabel('Condition')\n",
    "axes[2].set_ylabel('SRT (dB)')\n",
    "axes[2].set_title('SRT by Condition × Masker Type')\n",
    "axes[2].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[2].legend(title='Masker Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('crm_srt_analysis.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Save summary data\n",
    "df_crm_summary.to_csv('crm_summary.csv', index=False)\n",
    "print(\"\\nSummary saved to crm_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Analysis\n",
    "\n",
    "Additional visualizations and analyses to explore patterns in the data before collecting more subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Trial-by-trial SNR trajectory for each run\n",
    "print(\"Trial-by-trial SNR trajectories (adaptive staircase visualization):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_files = len(df_crm['filename'].unique())\n",
    "n_cols = min(3, n_files)\n",
    "n_rows = int(np.ceil(n_files / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows), squeeze=False)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (filename, group) in enumerate(df_crm.groupby('filename')):\n",
    "    ax = axes[idx]\n",
    "    trials = range(1, len(group) + 1)\n",
    "    ax.plot(trials, group['snr'].values, 'b-o', markersize=3, alpha=0.7)\n",
    "    \n",
    "    # Mark correct vs incorrect trials\n",
    "    correct = (group['target_color'].values == group['response_color'].values) & \\\n",
    "              (group['target_number'].values == group['response_number'].values)\n",
    "    ax.scatter(np.array(trials)[correct], group['snr'].values[correct], \n",
    "               c='green', s=20, zorder=5, label='Correct')\n",
    "    ax.scatter(np.array(trials)[~correct], group['snr'].values[~correct], \n",
    "               c='red', s=20, zorder=5, label='Incorrect')\n",
    "    \n",
    "    # Get SRT for this file\n",
    "    file_srt = df_crm_summary[df_crm_summary['filename'] == filename]['srt'].values[0]\n",
    "    ax.axhline(y=file_srt, color='purple', linestyle='--', alpha=0.7, \n",
    "               label=f'SRT={file_srt:.1f}')\n",
    "    \n",
    "    condition = group['condition'].iloc[0]\n",
    "    masker_type = group['masker_type'].iloc[0]\n",
    "    ax.set_title(f\"{filename}\\n{condition}, {masker_type}-gender\", fontsize=9)\n",
    "    ax.set_xlabel('Trial')\n",
    "    ax.set_ylabel('SNR (dB)')\n",
    "    ax.axhline(y=0, color='gray', linestyle=':', alpha=0.5)\n",
    "    if idx == 0:\n",
    "        ax.legend(fontsize=7, loc='upper right')\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(n_files, len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('crm_staircase_trajectories.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Response time analysis\n",
    "print(\"Response Time Analysis:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# RT distribution overall\n",
    "sns.histplot(df_crm['rt'], bins=30, kde=True, ax=axes[0])\n",
    "axes[0].set_xlabel('Response Time (s)')\n",
    "axes[0].set_title('Overall RT Distribution')\n",
    "axes[0].axvline(x=df_crm['rt'].median(), color='r', linestyle='--', \n",
    "                label=f'Median: {df_crm[\"rt\"].median():.2f}s')\n",
    "axes[0].legend()\n",
    "\n",
    "# RT by condition\n",
    "sns.boxplot(data=df_crm, x='condition', y='rt', ax=axes[1])\n",
    "axes[1].set_xlabel('Condition')\n",
    "axes[1].set_ylabel('Response Time (s)')\n",
    "axes[1].set_title('RT by Condition')\n",
    "\n",
    "# RT vs SNR (does RT increase at harder SNRs?)\n",
    "axes[2].scatter(df_crm['snr'], df_crm['rt'], alpha=0.3, s=10)\n",
    "# Add trend line\n",
    "z = np.polyfit(df_crm['snr'], df_crm['rt'], 1)\n",
    "p = np.poly1d(z)\n",
    "snr_range = np.linspace(df_crm['snr'].min(), df_crm['snr'].max(), 100)\n",
    "axes[2].plot(snr_range, p(snr_range), 'r-', alpha=0.8, label=f'Trend')\n",
    "axes[2].set_xlabel('SNR (dB)')\n",
    "axes[2].set_ylabel('Response Time (s)')\n",
    "axes[2].set_title('RT vs SNR')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('crm_response_time_analysis.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# RT statistics\n",
    "print(\"\\nRT Statistics by Condition:\")\n",
    "rt_stats = df_crm.groupby('condition')['rt'].agg(['mean', 'median', 'std']).round(2)\n",
    "rt_stats.columns = ['Mean RT (s)', 'Median RT (s)', 'RT SD (s)']\n",
    "print(rt_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Error pattern analysis\n",
    "print(\"Error Pattern Analysis:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate error types\n",
    "df_crm['color_correct'] = df_crm['target_color'] == df_crm['response_color']\n",
    "df_crm['number_correct'] = df_crm['target_number'] == df_crm['response_number']\n",
    "df_crm['both_correct'] = df_crm['color_correct'] & df_crm['number_correct']\n",
    "\n",
    "# Error breakdown\n",
    "def categorize_error(row):\n",
    "    if row['both_correct']:\n",
    "        return 'Correct'\n",
    "    elif row['color_correct'] and not row['number_correct']:\n",
    "        return 'Number Error'\n",
    "    elif not row['color_correct'] and row['number_correct']:\n",
    "        return 'Color Error'\n",
    "    else:\n",
    "        return 'Both Error'\n",
    "\n",
    "df_crm['error_type'] = df_crm.apply(categorize_error, axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Overall error breakdown\n",
    "error_counts = df_crm['error_type'].value_counts()\n",
    "colors = {'Correct': 'green', 'Number Error': 'orange', 'Color Error': 'blue', 'Both Error': 'red'}\n",
    "error_counts.plot(kind='bar', ax=axes[0], color=[colors.get(x, 'gray') for x in error_counts.index])\n",
    "axes[0].set_xlabel('Error Type')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Overall Error Breakdown')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Error rates by condition\n",
    "error_by_condition = pd.crosstab(df_crm['condition'], df_crm['error_type'], normalize='index') * 100\n",
    "error_by_condition.plot(kind='bar', ax=axes[1], color=[colors.get(x, 'gray') for x in error_by_condition.columns])\n",
    "axes[1].set_xlabel('Condition')\n",
    "axes[1].set_ylabel('Percentage')\n",
    "axes[1].set_title('Error Types by Condition (%)')\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "axes[1].legend(title='Error Type', bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('crm_error_analysis.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nError rates by condition:\")\n",
    "print(error_by_condition.round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 Individual run comparison plot\n",
    "print(\"Individual Run Comparison:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Sort by SRT for visualization\n",
    "df_sorted = df_crm_summary.sort_values('srt')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Create color map for conditions\n",
    "condition_colors = {'BM': 'blue', 'CI': 'red', 'HA': 'green', 'UNKNOWN': 'gray'}\n",
    "colors = [condition_colors.get(c, 'gray') for c in df_sorted['condition']]\n",
    "\n",
    "# Create hatching for masker type\n",
    "bars = ax.bar(range(len(df_sorted)), df_sorted['srt'], color=colors, \n",
    "              edgecolor='black', linewidth=1)\n",
    "\n",
    "# Add error bars for SD\n",
    "ax.errorbar(range(len(df_sorted)), df_sorted['srt'], yerr=df_sorted['sd'],\n",
    "            fmt='none', color='black', capsize=3)\n",
    "\n",
    "# Add hatching for different-gender maskers\n",
    "for idx, (bar, masker_type) in enumerate(zip(bars, df_sorted['masker_type'])):\n",
    "    if masker_type == 'different':\n",
    "        bar.set_hatch('//')\n",
    "\n",
    "ax.set_xticks(range(len(df_sorted)))\n",
    "ax.set_xticklabels([f.replace(subject_id + '_crm_', '').replace('.txt', '') \n",
    "                    for f in df_sorted['filename']], rotation=45)\n",
    "ax.set_xlabel('Run Number')\n",
    "ax.set_ylabel('SRT (dB)')\n",
    "ax.set_title(f'SRT by Run for {subject_id}\\n(Hatched = different-gender maskers)')\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=condition_colors[c], label=c) \n",
    "                   for c in df_sorted['condition'].unique()]\n",
    "legend_elements.append(Patch(facecolor='white', edgecolor='black', hatch='//', label='Diff-gender'))\n",
    "ax.legend(handles=legend_elements, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('crm_individual_runs.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4.5 Summary statistics and data quality checks\n",
    "print(\"Data Quality Summary:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nSubject: {subject_id}\")\n",
    "print(f\"Total CRM runs: {len(df_crm_summary)}\")\n",
    "print(f\"Total trials: {len(df_crm)}\")\n",
    "print(f\"\\nConditions tested: {', '.join(df_crm_summary['condition'].unique())}\")\n",
    "print(f\"Masker types: {', '.join(df_crm_summary['masker_type'].unique())}\")\n",
    "\n",
    "print(\"\\nRuns per condition:\")\n",
    "print(df_crm_summary['condition'].value_counts())\n",
    "\n",
    "print(\"\\nRuns per masker type:\")\n",
    "print(df_crm_summary['masker_type'].value_counts())\n",
    "\n",
    "print(\"\\nReversal count check (should be 14 for valid runs):\")\n",
    "rev_check = df_crm_summary[['filename', 'n_reversals', 'srt']]\n",
    "print(rev_check.to_string(index=False))\n",
    "\n",
    "# Flag any runs with fewer than 14 reversals\n",
    "low_rev = df_crm_summary[df_crm_summary['n_reversals'] < 14]\n",
    "if len(low_rev) > 0:\n",
    "    print(\"\\n⚠️  Warning: The following runs have fewer than 14 reversals:\")\n",
    "    print(low_rev[['filename', 'n_reversals']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OVERALL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nMean SRT across all runs: {df_crm_summary['srt'].mean():.2f} ± {df_crm_summary['srt'].std():.2f} dB\")\n",
    "print(f\"SRT range: {df_crm_summary['srt'].min():.2f} to {df_crm_summary['srt'].max():.2f} dB\")\n",
    "print(f\"\\nMean accuracy: {df_crm['both_correct'].mean()*100:.1f}%\")\n",
    "print(f\"Median response time: {df_crm['rt'].median():.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 1: Enhanced Phonetic & Distribution Analysis\n",
    "This section digs deeper into *why* errors happen (Feature Analysis) and improves visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 1.1 Phonetic Feature Analysis ---\")\n",
    "\n",
    "# Feature Map: Maps consonant characters to (Voicing, Place, Manner)\n",
    "# 1 = Feature Present/High, 0 = Feature Absent/Low\n",
    "feature_map = {\n",
    "    'b': (1, 1, 0), 'd': (1, 0, 0), 'g': (1, 0, 0),\n",
    "    'p': (0, 1, 0), 't': (0, 0, 0), 'k': (0, 0, 0),\n",
    "    'm': (1, 1, 1), 'n': (1, 0, 1),\n",
    "    'f': (0, 1, 2), 'v': (1, 1, 2), 's': (0, 0, 2), 'z': (1, 0, 2),\n",
    "    '#': (0, 0, 2), '_': (1, 0, 2), # Sh, Zh\n",
    "    '%': (0, 0, 3), '$': (1, 0, 3)  # Ch, J\n",
    "}\n",
    "\n",
    "def calculate_information_transfer(df, label_col, resp_col, feat_map):\n",
    "    # Filter for valid keys\n",
    "    valid = df[df[label_col].isin(feat_map.keys()) & df[resp_col].isin(feat_map.keys())]\n",
    "    if len(valid) == 0: return None\n",
    "    \n",
    "    features = ['Voicing', 'Place', 'Manner']\n",
    "    results = {}\n",
    "    \n",
    "    for i, feat_name in enumerate(features):\n",
    "        t_feat = valid[label_col].apply(lambda x: feat_map[x][i])\n",
    "        r_feat = valid[resp_col].apply(lambda x: feat_map[x][i])\n",
    "        # Calculate simple percent correct for that feature\n",
    "        acc = (t_feat == r_feat).mean() * 100\n",
    "        results[feat_name] = acc\n",
    "        \n",
    "    return pd.Series(results)\n",
    "\n",
    "if 'df_consonant' in locals():\n",
    "    feat_res = calculate_information_transfer(df_consonant, 'consonant_label', 'response_label', feature_map)\n",
    "    if feat_res is not None:\n",
    "        print(\"Feature Transmission Rates (% Correct):\")\n",
    "        print(feat_res.round(2))\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        feat_res.plot(kind='bar', color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "        plt.title('Phonetic Feature Transmission')\n",
    "        plt.ylabel('% Correct')\n",
    "        plt.ylim(0, 100)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 1.2 Advanced Heatmaps (Cluster Organized) ---\")\n",
    "\n",
    "def plot_clustered_matrix(df, target_col, resp_col, map_dict, title):\n",
    "    labels = [v for k, v in sorted(map_dict.items())]\n",
    "    \n",
    "    # Generate Counts\n",
    "    cm = pd.crosstab(df[target_col], df[resp_col])\n",
    "    # Reindex to ensure all labels exist\n",
    "    cm = cm.reindex(index=labels, columns=labels, fill_value=0)\n",
    "    # Normalize row-wise (Probability)\n",
    "    cm_prob = cm.div(cm.sum(axis=1), axis=0).fillna(0)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_prob, annot=True, fmt='.2f', cmap='rocket_r', \n",
    "                mask=(cm_prob==0), linewidths=0.5, linecolor='lightgray')\n",
    "    plt.title(title, fontsize=15)\n",
    "    plt.ylabel('Target')\n",
    "    plt.xlabel('Response')\n",
    "    plt.show()\n",
    "\n",
    "if 'df_vowel' in locals():\n",
    "    plot_clustered_matrix(df_vowel, 'vowel_label', 'response_label', vowel_map, \"Vowel Confusion Matrix\")\n",
    "\n",
    "if 'df_consonant' in locals():\n",
    "    plot_clustered_matrix(df_consonant, 'consonant_label', 'response_label', cons_map, \"Consonant Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 1.3 CRM Distributional Analysis (Violin Plot) ---\")\n",
    "\n",
    "if 'df_crm_summary' in locals() and not df_crm_summary.empty:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Violin plot shows density, Strip plot shows individual run data points\n",
    "    sns.violinplot(x='condition', y='srt', data=df_crm_summary, inner=None, color='lightgray', linewidth=0)\n",
    "    sns.stripplot(x='condition', y='srt', data=df_crm_summary, hue='masker_type', \n",
    "                  size=10, jitter=True, palette='bright', dodge=True, edgecolor='black', linewidth=1)\n",
    "    \n",
    "    plt.axhline(0, color='black', linestyle='--', alpha=0.3, label='0 dB SNR')\n",
    "    plt.title('Speech Reception Thresholds by Condition and Masker', fontsize=14)\n",
    "    plt.ylabel('SRT (dB SNR) - Lower is Better')\n",
    "    plt.legend(title='Masker Gender', bbox_to_anchor=(1.05, 1))\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"CRM Summary data not available for plotting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2: Exploratory & Statistical Analysis\n",
    "This section looks for temporal trends (fatigue/learning), performs statistical significance testing, and provides interactive exploration tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 2.1 Temporal Analysis (Fatigue / Learning Effects) ---\")\n",
    "\n",
    "def plot_temporal_trend(df, metric_col, title):\n",
    "    # Reset index to get global trial count\n",
    "    df_seq = df.reset_index(drop=True).reset_index().rename(columns={'index': 'trial'})\n",
    "    \n",
    "    # Calculate rolling average\n",
    "    df_seq['rolling'] = df_seq[metric_col].rolling(window=20).mean()\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.scatter(df_seq['trial'], df_seq[metric_col], alpha=0.2, color='gray', s=10, label='Raw Trial')\n",
    "    plt.plot(df_seq['trial'], df_seq['rolling'], color='red', linewidth=2, label='20-Trial Rolling Avg')\n",
    "    \n",
    "    # Simple Linear Regression for Trend\n",
    "    z = np.polyfit(df_seq['trial'], df_seq[metric_col].fillna(0), 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(df_seq['trial'], p(df_seq['trial']), \"b--\", alpha=0.8, label=f'Trend (Slope={z[0]:.4f})')\n",
    "    \n",
    "    plt.title(f'Temporal Trend: {title}')\n",
    "    plt.xlabel('Trial Sequence')\n",
    "    plt.ylabel(metric_col)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    if z[0] < -0.001: print(\"-> Potential Fatigue/Decline detected (Negative Slope)\")\n",
    "    if z[0] > 0.001: print(\"-> Potential Learning/Improvement detected (Positive Slope)\")\n",
    "\n",
    "if 'df_vowel' in locals():\n",
    "    plot_temporal_trend(df_vowel, 'score', \"Vowel Identification Accuracy\")\n",
    "\n",
    "if 'df_crm' in locals():\n",
    "    # Filter out ridiculously high SNRs (initial trials)\n",
    "    crm_clean = df_crm[df_crm['snr'] < 20]\n",
    "    plot_temporal_trend(crm_clean, 'snr', \"CRM SNR Tracking (All Runs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 2.2 Statistical Testing (ANOVA) ---\")\n",
    "\n",
    "if 'df_crm_summary' in locals():\n",
    "    # Filter valid data\n",
    "    stat_df = df_crm_summary[df_crm_summary['condition'] != 'Unknown'].dropna()\n",
    "    \n",
    "    if len(stat_df['condition'].unique()) > 1:\n",
    "        print(\"\\nRunning ANOVA on CRM SRTs (Condition + MaskerType)...\")\n",
    "        try:\n",
    "            model = ols('srt ~ C(condition) + C(masker_type)', data=stat_df).fit()\n",
    "            anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "            print(anova_table)\n",
    "            \n",
    "            if anova_table['PR(>F)'][0] < 0.05:\n",
    "                print(\"\\n-> Significant Condition Effect detected. Suggest Post-hoc t-tests.\")\n",
    "            else:\n",
    "                print(\"\\n-> No significant differences detected between conditions (p > 0.05).\")\n",
    "        except Exception as e:\n",
    "            print(f\"Stats error: {e} (Likely insufficient data points)\")\n",
    "    else:\n",
    "        print(\"Not enough conditions for ANOVA.\")\n",
    "        \n",
    "print(\"\\n--- 2.3 Advanced CRM Error Analysis ---\")\n",
    "# Breakdown errors by type: Color wrong? Number wrong? Both?\n",
    "\n",
    "if 'df_crm' in locals():\n",
    "    def classify_error(row):\n",
    "        c_ok = row['target_color'] == row['response_color']\n",
    "        n_ok = row['target_number'] == row['response_number']\n",
    "        if c_ok and n_ok: return 'Correct'\n",
    "        if c_ok and not n_ok: return 'Number Err'\n",
    "        if not c_ok and n_ok: return 'Color Err'\n",
    "        return 'Double Err'\n",
    "\n",
    "    df_crm['err_type'] = df_crm.apply(classify_error, axis=1)\n",
    "    \n",
    "    err_counts = df_crm.groupby(['condition', 'err_type']).size().unstack(fill_value=0)\n",
    "    # Normalize to percentage\n",
    "    err_pct = err_counts.div(err_counts.sum(axis=1), axis=0) * 100\n",
    "    \n",
    "    err_pct.plot(kind='bar', stacked=True, colormap='viridis', figsize=(10, 5))\n",
    "    plt.title('CRM Error Type Breakdown')\n",
    "    plt.ylabel('% of Trials')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, fixed\n",
    "\n",
    "print(\"--- 2.4 Interactive Data Explorer ---\")\n",
    "print(\"(If visualizations do not appear, ensure all previous cells ran successfully)\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1. VOWEL EXPLORER\n",
    "# -------------------------------------------------------\n",
    "def plot_vowel_metrics(talker_id, condition):\n",
    "    # scope check\n",
    "    if 'df_vowel' not in globals():\n",
    "        print(\"Error: df_vowel not loaded. Run Section 2 first.\")\n",
    "        return\n",
    "\n",
    "    data = df_vowel.copy()\n",
    "    \n",
    "    # Filter\n",
    "    if talker_id != 'All':\n",
    "        data = data[data['talker_id'] == talker_id]\n",
    "    if condition != 'All':\n",
    "        data = data[data['condition'] == condition]\n",
    "        \n",
    "    if len(data) == 0:\n",
    "        print(\"No data for this selection.\")\n",
    "        return\n",
    "\n",
    "    # Calculate Metrics\n",
    "    acc = data['score'].mean() * 100\n",
    "    mean_rt = data['rt'].mean()\n",
    "    \n",
    "    print(f\"--- Vowel Statistics (n={len(data)}) ---\")\n",
    "    print(f\"Accuracy:      {acc:.2f}%\")\n",
    "    print(f\"Mean Reaction: {mean_rt:.2f}s\")\n",
    "    \n",
    "    # Simple Bar Plot for Accuracy per Vowel\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    vowel_acc = data.groupby('vowel_label')['score'].mean() * 100\n",
    "    sns.barplot(x=vowel_acc.index, y=vowel_acc.values, palette='viridis')\n",
    "    plt.title('Accuracy by Phoneme')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.ylabel('% Correct')\n",
    "    plt.show()\n",
    "\n",
    "if 'df_vowel' in locals():\n",
    "    print(\"\\n>> VOWEL EXPLORER\")\n",
    "    talkers = ['All'] + sorted(list(df_vowel['talker_id'].unique()))\n",
    "    conds = ['All'] + sorted(list(df_vowel['condition'].unique()))\n",
    "    \n",
    "    interact(plot_vowel_metrics, talker_id=talkers, condition=conds)\n",
    "else:\n",
    "    print(\"Skipping Vowel Explorer (Data not loaded)\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2. CRM EXPLORER\n",
    "# -------------------------------------------------------\n",
    "def plot_crm_track(filename):\n",
    "    # scope check\n",
    "    if 'df_crm' not in globals():\n",
    "        print(\"Error: df_crm not loaded.\")\n",
    "        return\n",
    "        \n",
    "    data = df_crm[df_crm['filename'] == filename].copy()\n",
    "    if len(data) == 0: return\n",
    "    \n",
    "    # Calculate Correctness for color coding\n",
    "    data['correct'] = (data['target_color'] == data['response_color']) & \\\n",
    "                      (data['target_number'] == data['response_number'])\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(len(data)), data['snr'], 'b-', alpha=0.5)\n",
    "    \n",
    "    # Plot Correct as Green, Incorrect as Red\n",
    "    correct_trials = data[data['correct']]\n",
    "    incorrect_trials = data[~data['correct']]\n",
    "    \n",
    "    plt.scatter(correct_trials.index - data.index[0], correct_trials['snr'], c='green', label='Correct')\n",
    "    plt.scatter(incorrect_trials.index - data.index[0], incorrect_trials['snr'], c='red', label='Incorrect')\n",
    "    \n",
    "    plt.title(f\"Adaptive Track: {filename}\")\n",
    "    plt.xlabel(\"Trial\")\n",
    "    plt.ylabel(\"SNR (dB)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "if 'df_crm' in locals():\n",
    "    print(\"\\n>> CRM TRACK EXPLORER\")\n",
    "    files = sorted(list(df_crm['filename'].unique()))\n",
    "    interact(plot_crm_track, filename=files)\n",
    "else:\n",
    "    print(\"Skipping CRM Explorer (Data not loaded)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
